{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load RudyGilman_PS2_dofile.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "#########################################\n",
    "# Applied Econometrics, PS2             #\n",
    "# Rudy Gilman                           #\n",
    "# March 16, 2016                        #\n",
    "#########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import os, copy\n",
    "from causalinference import CausalModel\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "path = \"/home/rudebeans/Desktop/school_spring2016/applied_econometrics/\"\n",
    "\n",
    "#path = os.path.dirname(__file__)\n",
    "\n",
    "df = pd.read_stata(path+\"smoking2.dta\", convert_categoricals=False)\n",
    "#df = df.sample(n=20000, random_state=1985)\n",
    "df['intercept'] = 1 # Adding constant\n",
    "\n",
    "original = copy.deepcopy(df)\n",
    "\n",
    "\"\"\"\n",
    "This exercise examines the following research question: What is the effect of maternal smoking during pregnancy on infant birth weight and death? Feel free to work cooperatively and in groups. Each person must hand in his/her own problem set using his/her own words and interpretation of the results. Please include a concise summary of your empirical results when appropriate.\n",
    "\n",
    "We will analyze the following STATA data set:\n",
    "\n",
    "Data Source: smoking2.dta\n",
    "This STATA data extract is from the 1989 Linked National Natality-Mortality Detail Files, which are an\n",
    "annual census of births in the U.S., derived from Certificates of Live Birth. Information on subsequent infant death within a year of birth is derived from Death Certificates. This extract consists of all births in Pennsylvania in 1989. The observational unit of the data is the mother-infant outcome match.\n",
    "\n",
    "Data Notes:\n",
    "\n",
    "1. There are 139,149 observations and 32 variables. For this problem set, observations with missing values for any of the variables below were dropped from the original sample (about 17%).\n",
    "\n",
    "2. The key variables are:\n",
    "dbirwt = birth weight of the infant (in grams)\n",
    "death = indicator equal to one if the infant died within one-year of birth and zero, otherwise\n",
    "tobacco = indicator equal to one if the mother smoked during pregnancy and zero, otherwise.\n",
    "\n",
    "3. The relevant control variables are:\n",
    "\n",
    "Mother’s Attributes:\n",
    "dmage (mother’s age), dmeduc (mother’s educational attainment), mblack (indicator=1 if mother is black), motherr (=1 if neither black nor white), mhispan (=1 if Hispanic), dmar (=1 if mother is unmarried), foreignb (=1 if mother is foreign born)\n",
    "\n",
    "Father’s Attributes:\n",
    "dfage (father’s age), dfeduc (father’s education), fblack, fotherr, fhispan (racial indicators for father)\n",
    "\n",
    "Other Risky Behavior:\n",
    "alcohol (indicator=1 if mother drank alcohol during pregnancy), drink (# of drinks per week)\n",
    "\n",
    "Medical Care:\n",
    "tripre1, tripre2, tripre3 (indicators=1 if 1st prenatal care visit in 1st, 2nd, or 3rd trimester, respectively), tripre0 (=1 if no prenatal care visits), nprevist (total # of prenatal care visits)\n",
    "\n",
    "Pregnancy History and Maternal Health:\n",
    "first (=1 if first-born), dlivord (birth order), deadkids (# previous births where newborn died), disllb (months since last birth), preterm (=1 if previous birth premature or small for gestational age), pre4000 (=1 if previously had > 4000 gram newborn), plural (=1 if twins or greater birth), phyper (=1 if mother had pregnancy-associated hypertension), diabete (=1 if mother diabetic), anemia (=1 if mother anemic)\n",
    "\n",
    "Questions:\n",
    "\"\"\"\n",
    "print(\"\\n\\n\\n a) Under what conditions can one identify the average treatment effect of maternal smoking by comparing the unadjusted difference in mean birth weight of infants of smoking and non-smoking mothers? Under the assumption that maternal smoking is randomly assigned, estimate its impact on birth weight. Provide some evidence for or against the hypothesis that maternal smoking is randomly assigned.\")\n",
    "\n",
    "print(\"\\n\\n\\n Answer: If smoking is randomly assigned. Evidence against random assignment: Mothers who smoke probably do other things to lower birthweight, i.e. drink alcohol, do drugs. As we'll see below, this is the case. Evidence for random assignment: If these results were from a society / time period in which smoking wasn't known to be unhealthy, assignment might be random. As the means for smokers and nonsmokers shown below demonstrates, smokers and nonsmokers are very different in every way measured.\\n\\n\\n\")\n",
    "\n",
    "# I'm putting many of the answers in functions to avoid having to repeat them all in later questions.\n",
    "def do_a(df, variable):\n",
    "    df_smoke = df[df.tobacco == 1]\n",
    "    avgSmoke = np.mean(df_smoke[variable])\n",
    "\n",
    "    df_noSmoke = df[df.tobacco == 0]\n",
    "    avgNoSmoke = np.mean(df_noSmoke[variable])\n",
    "\n",
    "    smokeImpact = avgSmoke - avgNoSmoke\n",
    "    print(\"Estimated impact on \"+str(variable)+\" is {}\".format(smokeImpact))\n",
    "\n",
    "    t = ttest_ind(df_noSmoke[variable], df_smoke[variable])\n",
    "    print(\"Diff means t-test: {}\".format(t))\n",
    "    \n",
    "    mean_smokers = []\n",
    "    mean_nonsmokers = []\n",
    "    ts = []\n",
    "    for i in range(len(df.columns)):\n",
    "        var = df.columns[i]\n",
    "        m_s = np.mean(df_smoke[var])\n",
    "        mean_smokers.append(m_s)\n",
    "        m_ns = np.mean(df_noSmoke[var])\n",
    "        mean_nonsmokers.append(m_ns)\n",
    "        t = ttest_ind(df_noSmoke[var], df_smoke[var])[0]\n",
    "        ts.append(t)\n",
    "    means = pd.DataFrame({'mean_smokers':mean_smokers, 'mean_nonSmokers':mean_nonsmokers, 't_test':ts, 'variable':df.columns})\n",
    "    print(\"\\n\\n\\nComparing means in smoking and control groups\\n\\n\\n\")\n",
    "    \n",
    "    print means\n",
    "    \n",
    "do_a(df, 'dbirwt')\n",
    "\n",
    "print(\"\\n\\n\\n b) Suppose that maternal smoking is randomly assigned conditional on the other observable determinants of infant birth weight. What does this imply about the relationship between maternal smoking and unobservable determinants of birth weight conditional on the observables? Use a basic linear regression model to estimate the impact of smoking and report your estimates. Under what conditions is the average treatment effect identified?\\n\\n\\n\")\n",
    "\n",
    "def do_b(df, variable):\n",
    "    y = df[variable] \n",
    "    global X\n",
    "    X = df.loc[:,df.columns[df.columns.isin(['dbirwt','death', 'p','pg','weights'])==False]]\n",
    "    lm = sm.OLS(y, X).fit()\n",
    "    for_later_params = lm.params\n",
    "    print(\"\\n\\n\\nusing ols to estimate impact of smoking on {}\\n\\n\\n\".format(variable))\n",
    "    print(lm.summary())\n",
    "\n",
    "do_b(df, 'dbirwt')\n",
    "\n",
    "print(\"\\n\\n\\n Answer: Then unobserved determinants of birwt would be uncorrelated w tobacco conditional on the variables. As our linear model shows, effect of smoking reduced. There is a positive correlation between smoking and other factors that reduce birthweight. Average treatment effect IDed if treatment effects are homogenous. \\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\n c) Under the assumption of random assignment conditional on the observables, what are the sources of misspecification bias in the estimates generated by the linear model estimated in b)? Now use an approach in the spirit of multivariate matching. In other words, estimate the smoking effects using a flexible functional form for the control variables (e.g., higher order terms and interactions; include lots of controls as you would if you were estimating the propensity score, but just include them as controls in your regression). What are the benefits and drawbacks to this approach?\\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\n Answer: Misspecification bias in that we're not accounting for higher-order and interactive terms. Effect of smoking now reduced further. Benefits are we're controlling for higher order terms and interactions, reducing bias in our estimated effects. Drawbacks are the cumbersome nature of dragging around all these control variables, increase in the variance of our variable of interest (curse of dimensionality), and the fact that they somewhat distract from our true area of interest--smoking. \\n\\n\\n\") \n",
    "\n",
    "\n",
    "print(\"Note: We're using a random forest classifier to draw up a list of the most important variables with regards to predicting dbirwt. The most important variables will be interacted with eachother and used to make higher-order terms. \\n\\n\\n\") \n",
    "\n",
    "# Returns df with variables and importance, descending\n",
    "def get_imp(X,y):\n",
    "    rf = RandomForestClassifier(criterion='entropy', min_samples_split=40, n_estimators=50, random_state=99, max_depth=10)\n",
    "    rf.fit(X, y)\n",
    "    imp_var = rf.feature_importances_\n",
    "    imp_var = pd.DataFrame({'variable':X.columns, 'imp':imp_var}).sort('imp', ascending=False)\n",
    "    return(imp_var)\n",
    " \n",
    "imp_var=get_imp(X, df.dbirwt)    \n",
    "sig = list(imp_var[imp_var.imp > .001].variable)\n",
    "\n",
    "# JUst showing for own visualization purposes\n",
    "cols = list(imp_var.variable[0:5])\n",
    "\n",
    "print cols\n",
    "\n",
    "pp = df[cols].sample(500).dropna()\n",
    "print pp\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "#iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "g = sns.PairGrid(pp)\n",
    "g = g.map_upper(plt.scatter, alpha=.5)\n",
    "g = g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "g = g.map_diag(sns.distplot)\n",
    "#g = sns.pairplot(pp, kind='reg')\n",
    "\n",
    "# Rescaling axis. Why doesn't Seaborn do this for me automatically?\n",
    "axes = g.axes\n",
    "for i in range(len(cols)):\n",
    "    axes[i,i].set_ylim(np.min(pp[cols[i]]),np.max(pp[cols[i]]))\n",
    "    axes[i,i].set_xlim(np.min(pp[cols[i]]),np.max(pp[cols[i]]))\n",
    "#g.set(ylim=(0, 9))\n",
    "#g.set(xlim=(0, 9)) sets all axes to this extent\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sig.remove('tobacco')\n",
    "\n",
    "for_interact = df[df.columns[df.columns.isin(sig)==True]]\n",
    "\n",
    "# returns df w only interacted, higher-order variables\n",
    "def get_interact_higher(df):\n",
    "    # Interacting each significant variable with every other significant variable\n",
    "    for i in range(len(sig)): \n",
    "        for r in range(len(sig)):\n",
    "            if i < r:\n",
    "                colName = str(sig[i]) + str(sig[r])\n",
    "                df[colName] = df[sig[i]] * df[sig[r]]                           \n",
    "    # Making higher order variables up to ^4\n",
    "    for i in range(len(sig)): \n",
    "        for r in range(2,5):\n",
    "            df[str(sig[i])+str(r)] = (df[sig[i]])**r\n",
    "    dup = []\n",
    "    for i in range(len(df.columns)): \n",
    "        # Deleting identical cols\n",
    "        for r in range(len(df.columns)):\n",
    "            if (i < r) and (list(df[df.columns[i]]) == list(df[df.columns[r]])):\n",
    "                dup.append(df.columns[i])  \n",
    "        # Deleting columns w no variation\n",
    "        if np.std(df[df.columns[i]]) == 0:\n",
    "            print df.columns[i]\n",
    "            dup.append(df.columns[i])   \n",
    "    return df\n",
    "\n",
    "interacted = get_interact_higher(for_interact)\n",
    "\n",
    "# Choosing most important of interacted, higher order variables\n",
    "d = get_imp(interacted, df.dbirwt)\n",
    "\n",
    "sig = d[d.imp > 0.01].variable\n",
    "interacted = interacted[interacted.columns[interacted.columns.isin(sig)==True]]\n",
    "\n",
    "# This df contains all original values + all extras relevent to predicting dbirwt\n",
    "df_full_ols = pd.concat([df, interacted], axis = 1)\n",
    "df_full_ols['intercept'] = 1\n",
    "df_full_ols.to_pickle('df_full_ols.txt')\n",
    "\n",
    "df_full_ols = pd.read_pickle('df_full_ols.txt')\n",
    "\n",
    "# Running ols again w interacted, higher-order controls\n",
    "X = df_full_ols[df_full_ols.columns[df_full_ols.columns.isin(['dbirwt', 'death'])==False]]\n",
    "lm = sm.OLS(df_full_ols.dbirwt, X).fit()\n",
    "print(lm.summary())\n",
    "\n",
    "print(\"\\n\\n\\n d) Describe the propensity score approach to the problem of estimating the average causal effect of smoking when the treatment is randomly assigned conditional on the observables. How does it reduce the dimensionality “problem” of multivariate matching?\\n\\n\\n\") \n",
    "\n",
    "print(\"\\n\\n\\n Answer: By taking all the control variables and turning them into a composite index indicating an individual's liklihood of being a smoker. Now we don't have to match on all the previous control variables, just on this index. \\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\n e) Implement the propensity score approach to the evaluation problem using two methods: 1) control directly for the estimated propensity scores in a regression model; 2) use the estimated propensity score in a classification scheme to “stratify” the sample. Provide empirical evidence that your implementation is reasonable and evidence on the overlap of the observables of smokers and nonsmokers.  Present your findings and interpret the results. (This is an open-ended question, so show me what you know and be thoughtful).\\n\\n\\n\")\n",
    "\n",
    "print(\"Note: We're using a random forest classifier again to draw up a list of the most important variables with regards to identifying smokers. The most important variables will be interacted with eachother and used to make higher-order terms. We'll use a logistic regression to estimate liklihood of smoking.  \\n\\n\\n\") \n",
    "\n",
    "# not using these to predict smoking\n",
    "kill = ['tobacco', 'dbirwt', 'death'] \n",
    "X_lg = df[df.columns[df.columns.isin(kill) == False]]\n",
    "\n",
    "# Finding + interacting most important variables for predicting tobacco\n",
    "imp_var = get_imp(X_lg,df.tobacco)\n",
    "sig = list(imp_var[imp_var.imp > .01].variable)\n",
    "for_interact_lg = df[df.columns[df.columns.isin(sig)==True]]\n",
    "interacted_lg = get_interact_higher(for_interact_lg)\n",
    "\n",
    "# Choosing most important of interacted, higher order variables\n",
    "d = get_imp(interacted_lg, df.tobacco)\n",
    "sig = d[d.imp > 0.01].variable\n",
    "interacted_lg = interacted_lg[interacted_lg.columns[interacted_lg.columns.isin(sig)==True]]\n",
    "\n",
    "# This dataset contains all original variables + all extras relevent to predicting tobacco\n",
    "df_full_lg = pd.concat([df, interacted_lg], axis = 1)\n",
    "df_full_lg['intercept'] = 1\n",
    "df_full_lg.to_pickle('df_full_lg.txt')\n",
    "\n",
    "df_lg = pd.read_pickle('df_full_lg.txt')\n",
    "kill = ['tobacco', 'dbirwt', 'death'] \n",
    "X = df_lg[df_lg.columns[df_lg.columns.isin(kill) == False]]\n",
    "y = df_lg.tobacco\n",
    "\n",
    "lg = LogisticRegression(random_state=3)\n",
    "lg.fit(X,y)\n",
    "\n",
    "pred = lg.predict_proba(X)\n",
    "pred = [e[1] for e in pred]\n",
    "\n",
    "# Predicted logit values (propensity score), adding back to ORIGINAL df\n",
    "df['p'] = pred\n",
    "\n",
    "# This ugly function below finds the optimal p-score groups. On each pass, it splits the groups that don't satisfy the threshhold criterion set.\n",
    "def optimize_propensity_groups(df, threshhold):\n",
    "\n",
    "    def assign_groups(df):\n",
    "        num=2 \n",
    "        ls = sorted(list(df.p))\n",
    "        l = len(ls)/num\n",
    "\n",
    "        def get_group(x):\n",
    "            for i in range(num):\n",
    "                lower = ls[l*i]\n",
    "                if x >= lower and x <= ls[l*i+l-1]:\n",
    "                    return lower             \n",
    "        p = df.p           \n",
    "        pg = p.map(get_group)\n",
    "        df['pg'] = pg\n",
    "        return df\n",
    "\n",
    "    df = assign_groups(df) # First assignment of groups\n",
    "\n",
    "    def get_scores(df):\n",
    "        tots=[]\n",
    "        gs = sorted(df.pg.unique())\n",
    "        for i in range(len(df.pg.unique())):\n",
    "            groupId = gs[i]\n",
    "            d = df[df.pg==groupId]\n",
    "            d_smoke = d[d.tobacco==1]\n",
    "            d_noSmoke = d[d.tobacco==0]     \n",
    "            gScore = 0 \n",
    "            for c in range(len(d.columns)):\n",
    "                var = d.columns[c]\n",
    "                if var not in ['pg','tobacco']:      \n",
    "                    try:\n",
    "                        t = ttest_ind(d_smoke[var], d_noSmoke[var])[0]\n",
    "                    except:\n",
    "                        t = 2      \n",
    "                    if np.abs(t) < 1.96:\n",
    "                        gScore += 1            \n",
    "            groupScore = float(gScore) / float((len(d.columns)-2))\n",
    "            tots.append((groupId, groupScore))\n",
    "        return(tots)\n",
    "\n",
    "    def update_groups(df): # Performs one update pass across groups\n",
    "        scores = get_scores(df)\n",
    "        f = pd.DataFrame({})\n",
    "        for i in range(len(scores)):\n",
    "            groupId = scores[i][0]\n",
    "            s = df[df.pg==groupId]\n",
    "            if scores[i][1] < threshhold:\n",
    "                s = df[df.pg==groupId]\n",
    "                s = assign_groups(s)\n",
    "                f=pd.concat([f, s], axis=0)\n",
    "            else:\n",
    "                f=pd.concat([f, s], axis=0)\n",
    "        return f\n",
    "                   \n",
    "    def calc_final_score(df):\n",
    "        scores = get_scores(df)\n",
    "        groupNames = [i[0] for i in scores]\n",
    "        groupScores = [i[1] for i in scores]\n",
    "        match = pd.Series(groupScores)\n",
    "        match = match[match>=threshhold]\n",
    "        finalScore = float(len(match)) / float(len(groupScores))\n",
    "        return finalScore\n",
    "        \n",
    "    while calc_final_score(df) < threshhold: # Updating groups until threshhold met\n",
    "        df = update_groups(df)\n",
    "\n",
    "    print(calc_final_score(df))\n",
    "    print(len(get_scores(df)))   \n",
    "    print len(df.pg.unique())\n",
    "\n",
    "    return df\n",
    "\n",
    "df = optimize_propensity_groups(df, 0.7)\n",
    "\n",
    "df.to_pickle('df.txt')\n",
    "\n",
    "# This dataframe has p-scores and p-groups\n",
    "df = pd.read_pickle('df.txt')\n",
    "df_y = df[(df.dmage<=32)&(df.dmage>=16)]\n",
    "\n",
    "# Trimming off outliers (top and bottom .10)\n",
    "def trim(df, amount):\n",
    "    df = df.dropna().sort_values(['p'])\n",
    "    tenPerc = int(len(df)/(100.0/float(amount)))\n",
    "    minP = df.iloc[tenPerc]['p']\n",
    "    maxP = df.iloc[len(df)-tenPerc]['p']\n",
    "    df = df[(df.p>minP)&(df.p<maxP)]\n",
    "    return df\n",
    "    \n",
    "df = trim(df, .10)\n",
    "df_y = trim(df_y, .10)\n",
    "\n",
    "print(\"\\n\\n\\n Using propensity score as control in original regression. \\n\\n\\n\")\n",
    "y = df.dbirwt\n",
    "pX = df.loc[:,['p', 'tobacco', 'intercept']]\n",
    "lm_p = sm.OLS(y,pX).fit()\n",
    "print(lm_p.summary())\n",
    "\n",
    "# Repeating for young dataset\n",
    "y = df_y.dbirwt\n",
    "pX = df_y.loc[:,['p', 'tobacco', 'intercept']]\n",
    "lm_p = sm.OLS(y,pX).fit()\n",
    "# Results moved to later question\n",
    "#print('\\n\\n\\n YOUNG:\\n\\n\\n')\n",
    "#print(lm_p.summary())\n",
    "\n",
    "df_smoke = df[df.tobacco == 1]\n",
    "df_noSmoke = df[df.tobacco == 0]\n",
    "\n",
    "# Boxplot\n",
    "print(\"\\n\\n\\n Showing overlap btwn our groups. There's overlap, but we're clearly dealing with two very different groups here \\n\\n\\n\")\n",
    "ax = sns.boxplot(x='tobacco', y='p', data=df)\n",
    "ax.set_title('pscore overlap: boxplot')\n",
    "sns.plt.show()\n",
    "ax.cla()\n",
    "\n",
    "# Histogram\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "h1 = ax.hist(list(df_smoke.p), bins=30, normed=True, alpha=.5)\n",
    "h2 = ax.hist(list(df_noSmoke.p), bins=30, normed=True, alpha=.5)\n",
    "ax.set_title('p-score overlap: kdensity')\n",
    "ax.set_xlabel('estimated propensity')\n",
    "ax.set_ylabel('normalized frequency')\n",
    "ax.legend(['smokers', 'nonsmokers'])\n",
    "plt.show()\n",
    "fig.clf()\n",
    "\n",
    "\n",
    "ks = stats.ks_2samp(df_smoke.p, df_noSmoke.p)\n",
    "print(\"\\n\\n The kalashnikov smirnoff test shows that our p-score distributions are very much not the same: {}\\n\\n\".format(ks))\n",
    "\n",
    "# Matching by p-score group and comparing TEs\n",
    "def compare_pg(df):\n",
    "    print(\"\\n\\nMatching by p-score group and comparing TEs\\n\\n\")\n",
    "    pg_strat = pd.DataFrame(columns=['groupName','TE','TE_tscore','ks'])\n",
    "    for i in range(len(df.pg.unique())):\n",
    "        pg = df.pg.unique()[i]\n",
    "        d = df[df.pg==pg]\n",
    "        d_smoke = d[d.tobacco==1]\n",
    "        d_noSmoke = d[d.tobacco==0]\n",
    "        try:\n",
    "            t = ttest_ind(d_smoke.dbirwt, d_noSmoke.dbirwt)[0]\n",
    "        except:\n",
    "            t = np.nan\n",
    "        TE = np.mean(d_smoke.dbirwt) - np.mean(d_noSmoke.dbirwt)\n",
    "        try:\n",
    "            ks = stats.ks_2samp(d_smoke.p, d_noSmoke.p)\n",
    "        except: \n",
    "            ks = np.nan\n",
    "        pg_strat = pg_strat.append({'groupName':pg, 'TE':TE, 'TE_tscore':t, 'ks':ks}, ignore_index=True)\n",
    "    return pg_strat\n",
    "   \n",
    "print(\"As we can see in the classification table below, this approach was reasonable: In the majority of our groups, we can't reject the KS-test null that the p-score distributions are the same. As we can see in the box plot above, we started with decent overlap btwn the smokers and controls.\\n\\n\\n\" )   \n",
    "   \n",
    "print(compare_pg(df))\n",
    "\n",
    "print(\"\\n\\n\\nf) Now use the estimated propensity scores to reweigh the outcomes and estimate: i) the population average treatment effect; and ii) the average treatment effect among the treated. Compare your estimates to those in e) and interpret your findings. What are the benefits and drawbacks of approaches that use the estimated propensity scores as weights?\\n\\n\\n\")\n",
    "\n",
    "# getting tot effect:\n",
    "def do_f(df):\n",
    "\n",
    "    print(\"\\n\\n\\n Finding TOT effects \\n\\n\\n\")\n",
    "    X = df.loc[:, df.columns[df.columns.isin(['dbirwt','tobacco','death'])==False]]\n",
    "    df['weights'] = 1\n",
    "    df_smoke = df[df.tobacco==1]\n",
    "    df_noSmoke = df[df.tobacco==0]\n",
    "    df_noSmoke.weights = df_noSmoke.weights * (df_noSmoke.p / (1.0-df_noSmoke.p) )\n",
    "    df = pd.concat([df_smoke, df_noSmoke], axis=0)\n",
    "    x = df.loc[:,['tobacco','intercept']]\n",
    "    wls = sm.WLS(df.dbirwt, x, weights=df.weights).fit()\n",
    "    print(wls.summary())\n",
    "    \n",
    "    # Histogram\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    h1 = ax.hist(list(df_smoke.p), weights=list(df_smoke.weights), bins=30, normed=True, alpha=.5)\n",
    "    h2 = ax.hist(list(df_noSmoke.p), weights=list(df_noSmoke.weights), bins=30, normed=True, alpha=.5)\n",
    "    ax.set_title('TOT Weighted p-score distribution by treatment')\n",
    "    ax.set_xlabel('estimated propensity')\n",
    "    ax.set_ylabel('normalized frequency')\n",
    "    ax.legend(['smokers', 'nonsmokers'])\n",
    "    plt.show()\n",
    "    fig.clf()\n",
    "    \n",
    "    # getting ATE:\n",
    "    print(\"\\n\\n\\n Finding ATE effects \\n\\n\\n\")\n",
    "    X = df.loc[:, df.columns[df.columns.isin(['dbirwt','tobacco','death'])==False]]\n",
    "    df['weights'] = 1\n",
    "    df_smoke = df[df.tobacco==1]\n",
    "    df_noSmoke = df[df.tobacco==0]\n",
    "    df_noSmoke.weights = (df_noSmoke.p / (1.0-df_noSmoke.p) )\n",
    "    df_smoke.weights =  (1 / df_smoke.p)\n",
    "    df = pd.concat([df_smoke, df_noSmoke], axis=0)\n",
    "    x = df.loc[:,['tobacco','intercept']]\n",
    "    wls = sm.WLS(df.dbirwt, x, weights=df.weights).fit()\n",
    "    print(wls.summary())\n",
    "    \n",
    "    # Histogram: \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    h1 = ax.hist(list(df_smoke.p), weights=list(df_smoke.weights), bins=30, normed=True, alpha=.5)\n",
    "    h2 = ax.hist(list(df_noSmoke.p), weights=list(df_noSmoke.weights), bins=30, normed=True, alpha=.5)\n",
    "    ax.set_title('ATE Weighted p-score distribution by treatment')\n",
    "    ax.set_xlabel('estimated propensity')\n",
    "    ax.set_ylabel('normalized frequency')\n",
    "    ax.legend(['smokers', 'nonsmokers'])\n",
    "    plt.show()\n",
    "    fig.clf()\n",
    "    \n",
    "do_f(df)\n",
    "\n",
    "print(\"Answer: Our estimates are similar to those found in e). An advantage is that all observations can be used. \\n\\n\\n\")\n",
    "\n",
    "print(\"g) A more informative way to describe the birth weight effects of smoking is to estimate the “nonparametric” conditional mean of birth weight as a function of the estimated propensity score, for smokers and non-smokers. To do this simply, stratify the smokers into 100 equal-sized cells based on their propensity scores and calculate the mean birth weight and propensity score in each cell. Do the same for the non-smokers. Plot these 2 conditional mean functions on the same graph, with the mean scores on the x-axis and mean birth weight on the y-axis. Interpret your findings and relate them to the results in e) and f). Now redo the above but use 200 equal-sized cells for smokers and non-smokers together – i.e., each cell should contain 1/200th’s of the data, with some cells containing very few smokers and other cells containing mostly smokers.\")\n",
    "\n",
    "print(\"\\n\\n\\n Answer: Looks similar to what we found earlier. Relationship btwn p-score and dbirwt looks linear. Treatment effects look homogenous. Breaking p-scores into 200 groups leads to more noise, as there are some groups with very few individuals.\")\n",
    "\n",
    "# breaks df.p into equally sized groups based on percentile\n",
    "def assign_groups(df, num):\n",
    "    ls = sorted(list(df.p))\n",
    "    l = int(len(ls)/num)\n",
    "    def get_group(x):\n",
    "        for i in range(num):\n",
    "            lower = ls[l*i]\n",
    "            if x > lower and x <= ls[l*i+l-1]:\n",
    "                return lower          \n",
    "    p = df.p           \n",
    "    pg = p.map(get_group)\n",
    "    df['pg'] = pg.fillna(np.min(pg))\n",
    "    return df\n",
    "    \n",
    "# returns small dataframe with p-score groups and dbirwt means for graphing\n",
    "def get_cond_means(df):\n",
    "    means_s = []\n",
    "    means_ns = []\n",
    "    pg = df.pg.unique()\n",
    "    for i in range(len(pg)):\n",
    "        pg_i = pg[i]\n",
    "        d = df[df.pg==pg_i]\n",
    "        d_s = d[d.tobacco==1]\n",
    "        d_ns = d[d.tobacco==0]     \n",
    "        m_s = np.mean(d_s.dbirwt)\n",
    "        m_ns = np.mean(d_ns.dbirwt)       \n",
    "        means_s.append(m_s)\n",
    "        means_ns.append(m_ns)\n",
    "    cm = pd.DataFrame({'means_s':means_s, 'means_ns':means_ns, 'pg':pg})\n",
    "    return cm\n",
    "\n",
    "# For making scatterplots. y, x must both be array\n",
    "def scat(x, ys, title=None, legend=None):\n",
    "    c = ['blue', 'red', 'green', 'yellow', 'purple']\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(len(ys)):\n",
    "        ax.scatter(x, ys[i], c=c[i])\n",
    "    ax.set_title(title)\n",
    "    y=''\n",
    "    for h in ys: y += str(h.name)+', '   \n",
    "    ax.set_ylabel(str(y))\n",
    "    ax.set_xlabel(str(x.name))\n",
    "    ax.legend(legend)\n",
    "    plt.show()\n",
    "    fig.clf()\n",
    "\n",
    "def do_g(df):\n",
    "    # making scatter for 100 group    \n",
    "    cm_100 = get_cond_means(assign_groups(df, 100))\n",
    "    scat(cm_100.pg, [cm_100.means_ns, cm_100.means_s], 'mean birwt by p-group: 100', ['nonsmokers', 'smokers'])\n",
    "\n",
    "    # making scatter for 200 group\n",
    "    cm_200 = get_cond_means(assign_groups(df, 200))\n",
    "    scat(cm_200.pg, [cm_200.means_ns, cm_200.means_s], 'mean birwt by p-group: 100', ['nonsmokers', 'smokers'])\n",
    "\n",
    "do_g(df)\n",
    "\n",
    "print(\"\\n\\n\\n h) Low birth weight births (less than 2500 grams) are considered particularly undesirable since they comprise a large share of infant deaths. Redo g) using an indicator for low birth weight birth as the outcome of interest. Interpret your findings.\\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\n Answer: Looks like smokers have a higher proportion of lwbwt infants, and that the proportion of lwbwt infants increases linearly with p-score. Again, 200 group is noisier.\")\n",
    "\n",
    "def low_bw_dummy(x):\n",
    "        if x >= 2500.0:\n",
    "            return 0 \n",
    "        elif x < 2500.0:\n",
    "            return 1                  \n",
    "df['dbirwt_d'] = df.dbirwt.map(low_bw_dummy)\n",
    "\n",
    "# returns small dataframe with p-score groups and dbirwt means for graphing\n",
    "def get_lbw(df):\n",
    "    lowbw_s = []\n",
    "    lowbw_ns = []\n",
    "    pg = df.pg.unique()\n",
    "    for i in range(len(pg)):\n",
    "        pg_i = pg[i]\n",
    "        d = df[df.pg==pg_i]\n",
    "        d_s = d[d.tobacco==1]\n",
    "        d_ns = d[d.tobacco==0]     \n",
    "        m_s = float(len(d_s[d_s.dbirwt_d ==1])) / float(len(d_s))\n",
    "        m_ns = float(len(d_ns[d_ns.dbirwt_d ==1])) / float(len(d_ns))\n",
    "        lowbw_s.append(m_s)\n",
    "        lowbw_ns.append(m_ns)\n",
    "    cm = pd.DataFrame({'lowbw_s':lowbw_s, 'lowbw_ns':lowbw_ns, 'pg':pg})\n",
    "    return cm\n",
    "      \n",
    "lbw_100 = get_lbw(assign_groups(df, 100))\n",
    "scat(lbw_100.pg, [lbw_100.lowbw_ns, lbw_100.lowbw_s], 'lowbwt perc of total by p-group: 100', ['nonsmokers', 'smokers'])\n",
    "\n",
    "lbw_200 = get_lbw(assign_groups(df, 200))\n",
    "scat(lbw_200.pg, [lbw_200.lowbw_ns, lbw_200.lowbw_s], 'lowbwt perc of total by p-group: 200', ['nonsmokers', 'smokers'])\n",
    "\n",
    "print(\"\\n\\n\\n i) Estimate the impact of maternal smoking on infant death using the methods in parts a), b), and g) (using 50 equal-sized cells, for smokers and non-smokers together). Interpret your findings. From your results, what might you conclude about the relationship between smoking and infant death? \\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Answer: It doesn't look like there's a statistically significant relationship btwn smoking and infant death. There is, however, a clearly positive correlation btwn p-score and infant death \\n\\n\\n\")\n",
    "\n",
    "# returns small dataframe with p-score groups and death props for graphing\n",
    "def get_death(df):\n",
    "    lowbw_s = []\n",
    "    lowbw_ns = []\n",
    "    pg = df.pg.unique()\n",
    "    for i in range(len(pg)):\n",
    "        pg_i = pg[i]\n",
    "        d = df[df.pg==pg_i]\n",
    "        d_s = d[d.tobacco==1]\n",
    "        d_ns = d[d.tobacco==0]     \n",
    "        m_s = float(len(d_s[d_s.death ==1])) / float(len(d_s))\n",
    "        m_ns = float(len(d_ns[d_ns.death ==1])) / float(len(d_ns))\n",
    "        lowbw_s.append(m_s)\n",
    "        lowbw_ns.append(m_ns)\n",
    "    cm = pd.DataFrame({'death_s':lowbw_s, 'death_ns':lowbw_ns, 'pg':pg})\n",
    "    return cm\n",
    "\n",
    "# finding simple diff in means in effect of smoking on death\n",
    "print(\"Repeating a) for infant death \\n\\n\\n\")\n",
    "do_a(original, 'death')\n",
    "\n",
    "print(\"Repeating b) for infant death \\n\\n\\n\")\n",
    "# running ols, effect of smoking on death\n",
    "do_b(original, 'death')\n",
    "\n",
    "print(\"Repeating g) for infant death \\n\\n\\n\")\n",
    "# graphing\n",
    "df50 = assign_groups(df, 50)\n",
    "death_100 = get_death(df50)\n",
    "scat(death_100.pg, [death_100.death_ns, death_100.death_s], 'perc infant death by p-group', ['nonsmokers', 'smokers'])\n",
    "\n",
    "print(\"\\n\\n\\n j) Smoking rates vary over the life-cycle of women. Plot the sample sizes and smoking rates by the age of the women in the sample. Now, separately for smoking and non-smoking women but on the same graph, plot the average birth weight of their infants by the age of the mother. Describe what you see.\\n\\n\\n\")\n",
    "\n",
    "print(\"Answer: smoking is most popular among 19 yr olds, and becomes steadily less popular afterwards. Sample size by age group looks approximately normally distributed with mean at 27. Ppl younger than 15 and older than 40 are not well represented. Avg birthweight increases then decreases for both smokers and nonsmokers, peaking around age 30. The treatment effect differs significantly with age, with older women affected more negatively by smoking. There's significant noise amongst women younger than 15 and older than 40. \\n\\n\\n\")\n",
    "\n",
    "pt = pd.pivot_table(df, ['tobacco'], 'dmage', aggfunc=np.mean)\n",
    "scat(pt.index, [pt.tobacco], 'perc smoker by age', ['all'])\n",
    "\n",
    "pt = pd.pivot_table(df, ['intercept'], 'dmage', aggfunc=np.sum)\n",
    "scat(pt.index, [pt.intercept], 'sample size by age', ['all'])\n",
    "\n",
    "df_s = df[df.tobacco==1]\n",
    "df_ns = df[df.tobacco==0]\n",
    "pt_s = pd.pivot_table(df_s, ['dbirwt'], 'dmage', aggfunc=np.mean)\n",
    "pt_ns = pd.pivot_table(df_ns, ['dbirwt'], 'dmage', aggfunc=np.mean)\n",
    "\n",
    "# scatter\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(pt_ns.index, pt_ns.dbirwt, c='blue')\n",
    "ax.scatter(pt_s.index, pt_s.dbirwt, c='red')\n",
    "ax.set_title('avg birthweight by mage')  \n",
    "ax.set_ylabel('dbirwt')\n",
    "ax.set_xlabel('age')\n",
    "ax.legend(['nonsmokers', 'smokers'])\n",
    "plt.show()\n",
    "fig.clf()\n",
    "\n",
    "print(\"\\n\\n\\n k) For the sample of women aged 16 to 32 (116,243 observations), redo parts a), b), e), f), g) and i).  How do your findings contrast with your findings from the overall sample, if at all?\\n\\n\\n\")\n",
    "\n",
    "print(\" As shown below, findings are substantively the same.\\n\\n\\n\")\n",
    "\n",
    "df_young = original[(original.dmage<=32)&(original.dmage>=16)]\n",
    "\n",
    "print(\"\\n\\nRepeating a) for young women \\n\\n\\n\")\n",
    "# parts a, b\n",
    "do_a(df_young, 'dbirwt')\n",
    "\n",
    "print(\"\\n\\nRepeating b) for young women \\n\\n\\n\")\n",
    "do_b(df_young, 'dbirwt')\n",
    "\n",
    "print(\"\\n\\nRepeating e) for young women \\n\\n\\n\")\n",
    "# part e)\n",
    "print(\"\\n\\n\\n Using propensity score as control in original regression. \\n\\n\\n\")\n",
    "print(lm_p.summary()) # model built in part e), just printing summary here\n",
    "print(compare_pg(df_y))\n",
    "\n",
    "print(\"\\n\\n\\nRepeating f) for young women \\n\\n\\n\")\n",
    "# part f)\n",
    "do_f(df_y)\n",
    "\n",
    "print(\"\\n\\nRepeating g) for young women \\n\\n\\n\")\n",
    "# part g)\n",
    "do_g(df_y)\n",
    "\n",
    "print(\"\\n\\nRepeating i) for young women \\n\\n\\n\")\n",
    "# part i)\n",
    "# finding simple diff in means in effect of smoking on death\n",
    "do_a(df_y, 'death')\n",
    "# running ols, effect of smoking on death\n",
    "do_b(df_y, 'death')\n",
    "# graphing\n",
    "df50 = assign_groups(df_y, 50)\n",
    "death_100 = get_death(df50)\n",
    "scat(death_100.pg, [death_100.death_ns, death_100.death_s], 'perc infant death by p-group', ['nonsmokers', 'smokers'])\n",
    "\n",
    "print(\"\\n\\n\\n l) Concisely and coherently summarize all of your findings. In this summary, describe the estimated effects of maternal smoking on infant birth weight and infant mortality and whether you think your “best” estimate of the effects of smoking is credibly identified. State why or why not.\\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\n Using a few different techniques, we reliably measured the effect of smoking on birthweight at around -200 g. As shown in the boxplot and kdensity plots earlier, however, smokers and nonsmokers are very different in a lot of ways. We tried to control for this, and did to some extent, but the question still remains: Can we interpret this effect as causal? In my opinion, we've shown an upper bound for what the effect of smoking on dbirwt might be--the true effects may be much lower. \\n\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
